# ShareMood
## Assignment02: Usability Testing by Rebecca Lin

### Introduction
Moodtrack Social Diary is a mobile application that serves as a mood tracker with social functionality. Users can choose to post in their own personal diary and/or engage with other users who are also sharing their moods on the app's community feed. 

As per usability.gov, "a usability test is intended to determine the extent an interface facilitates a user’s ability to complete routine tasks." To better improve the app from the user's perspective, the test proposed three tasks that looked at usability issues I found from my heuristic reviews that addressed the goals of the app (mood tracking and social support): 

**1. Make a new mood entry (i.e. "Record that you are sad.")**

* In the heuristic review, I noted a conflict with heuristic 7 (flexibility and efficiency of use). An integral part of the app is that the user is able to keep track of moods and share posts, but the button to create a new post is buried within the "Me" tab, making the app less efficient to use. Having the button readily available in the header at all times while browsing the app would be more intuitive to the app design and functions. I wanted to see how easily the participant could record a mood, and what buttons might be confusing in the process.

**2. Be able to analyze past mood logs (i.e. "Find the reason you were sad last week.")** 

A main selling point of the app is that the mood tracker is easy to use so that the user can reference past logs and also choose to share the log with others, like his or her healthcare provider. 

* The log is not intuitive to use at first glance; conflicting with heuristic 4 (consistency and standards), the buttons on the mood log make it difficult to explore moods by date. The "+" and "-" signs are not as intuitive as a magnifying glass for zooming in/out on the timeline and could potentially confuse the user when trying to make a new post. 
* Also, it takes time for the user to learn that tapping certain points or words can lead them to further results; in accordance with heuristic 6 (recognition rather than recall), it would help to redesign buttons so that they call out an action, rather than having the user have to remember how the app functions. 

Together, these make for a clunky user experience. I wanted to see the most intuitive method the user would choose in analyzing his/her logs.

**3. Be able to engage with other users on the app (i.e. "Show support to another user.")** 

The last unique feature of the app is that it provides social functionality so that one can access or give support when desired. 

* The "Everyone" news feed violates heuristic 8 (aesthetic and minimalist design), as it is extremely text heavy and cluttered. There is little negative space to differentiate users' posts, and it makes the statuses hard to read. To facilitate social interaction on the app, it is necessary for the user to be easily drawn to what others have to say, but the current design does not do that. 
* Also, this task asks the participant to see if the app's mood coloring system is intuitive. Moodtrack uses a spectrum of 5 different colors to indicate varying levels of mood, but because the colors are not very intuitively graded (like in a gradient), it is difficult for the user to remember what feelings each color corresponds to and makes the posts on the news feed less meaningful. It would help to have icons or emoticons associated with each color to remember the emotion, rather than staying so text heavy. 
* Lastly, with heuristic 2 (match between system and the real world), the app is not intuitively modeled like typical social media sites, so I wanted to see if the participant could be able to find social functions to follow other users and comment on others' posts. 


As a pilot test to test the setting and materials, I conducted an onsite usability test using a live version of Moodtrack located on my iPhone. A minimalist portable test lab was set up in my apartment room at UCLA. A laptop using the webcam feature captured the participant's face, comments, and administrator, while the iPhone's native screen recording feature recorded the participant's onscreen performance. Only the test administrator (me) and participant were present in the room. The session captured the participant’s navigational choices, task completion rates, comments, overall satisfaction ratings, questions and feedback.

### Links

The usability materials [here](https://forms.gle/53kKHB8Gvb1UqXtRA).

The test administrator/participant face video [here](https://youtu.be/cEQ2l8Cl6HE).

The onscreen pilot test video [here](https://youtu.be/7zfM1AAS5Mo).

### Summary

The pilot test was insightful in seeing how the user would approach the app at first glance. I learned that even though you may prepare much for a pilot test, the purpose of the pilot test is to catch any issues with the UT before conducting real surveys; I noticed a couple of issues with the form and also realized that I should have better formulated what to say beyond the script. Making sure to check the environment was better controlled would have also helped with distractions (i.e. making sure the participant's phone was off as well). Of course, administering a test is tricky in practice, but I felt like I overall handled the participant's comments and worries well. In the future, I would like to run through my materials and set up thoroughly before administering it. Furthermore, even though this session went smoothly, I would like to continue to work on having objective comments/guiding questions prepared in the case that the participant runs into any troubles. 


